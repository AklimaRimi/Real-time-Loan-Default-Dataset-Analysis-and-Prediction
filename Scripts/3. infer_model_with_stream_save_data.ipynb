{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f6b6971-f2b6-4714-ae75-815aa090cb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kafka-python in /opt/conda/lib/python3.11/site-packages (2.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install kafka-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a002ad6e-b286-4b28-b557-e25d65399c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, from_json\n",
    "from kafka import KafkaProducer\n",
    "import json\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType, StringType, BooleanType\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as t\n",
    "from pyspark.sql import SparkSession\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.ml import feature as MF\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, LinearSVC, GBTClassifier\n",
    "from pyspark.ml.feature import ChiSqSelector\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "\n",
    "KAFKA_BROKER = \"kafka:9092\"\n",
    "TOPIC = \"Group3-Loan-Data9\"\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "266e7698-1027-47fa-ac67-6085990f72d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Capstone\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4da79064-543d-419f-9c00-ba2ba492ef5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", KAFKA_BROKER) \\\n",
    "    .option(\"subscribe\", TOPIC) \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8368c1d8-2630-4ea9-aae1-06602c91d76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('Loan_Default.csv',header=True,inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "edc60c9c-8398-48e1-b794-fab781e9a49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ecf9bbfc-8ac8-46bf-b396-3a7ee5786e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_df = data.selectExpr(\"CAST(value AS STRING)\")\\\n",
    "    .select(from_json(col(\"value\"), sc).alias(\"data\")).select(\"data.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73e201e1-906b-4591-8b94-27e5b2b5cfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(json_df.isStreaming) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3dcf412-b2e6-4d7b-b304-cfff91ee8cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "json_df = json_df.drop('ID','year')\n",
    "processed_df = json_df.withColumn(\"Age_range_1\", F.split(F.col(\"age\"), \"-\")[0]) \\\n",
    "                      .withColumn(\"Age_range_2\", F.split(F.col(\"age\"), \"-\")[1]) \\\n",
    "                      .drop(\"age\")\n",
    "\n",
    "processed_df.createOrReplaceTempView(\"df\")\n",
    "\n",
    "\n",
    "col_to_double = ['loan_amount', 'rate_of_interest', 'Interest_rate_spread', 'Upfront_charges',\n",
    "                 'term', 'income', 'dtir1', 'Status', 'LTV', 'Credit_Score', 'property_value',\n",
    "                 'Age_range_1', 'Age_range_2']\n",
    "\n",
    "col_to_string = list(set(processed_df.columns) - set(col_to_double))\n",
    "\n",
    "query = \", \".join([f\"CAST(`{col}` AS DOUBLE) AS `{col}`\" for col in col_to_double])\n",
    "query1 = \", \".join(f\"CAST(`{col}` AS STRING) AS `{col}`\" for col in col_to_string)\n",
    "\n",
    "df_new = spark.sql(f\"SELECT {query}, {query1} FROM df\")\n",
    "\n",
    "\n",
    "df_new.createOrReplaceTempView(\"df\")\n",
    "\n",
    "df_new = spark.sql(\"\"\"\n",
    "    SELECT *, \n",
    "           COALESCE(rate_of_interest, 0) AS rate_of_interest_, \n",
    "           COALESCE(Interest_rate_spread, 0) AS Interest_rate_spread_, \n",
    "           COALESCE(Upfront_charges, 0) AS Upfront_charges_, \n",
    "           COALESCE(dtir1, 0) AS dtir1_ \n",
    "    FROM df\n",
    "\"\"\")\n",
    "df_new = df_new.drop(\"rate_of_interest\", \"Interest_rate_spread\", \"Upfront_charges\", \"dtir1\")\n",
    "\n",
    "df_new = df_new.dropna()\n",
    "indexer_model = MF.StringIndexerModel.load(\"indexer_model\")\n",
    "\n",
    "df_indexed = indexer_model.transform(df_new)\n",
    "\n",
    "df_indexed = df_indexed.drop(*col_to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b675e6e4-2eba-4445-aaea-2d5d8f9fe85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler_df = MF.VectorAssembler(\n",
    "    inputCols=[c for c in df_indexed.columns if c != \"Status\"],\n",
    "    outputCol=\"features\"\n",
    ").transform(df_indexed)\n",
    "# assembler_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7835d6dd-9ec4-4df1-802b-e9e0c6878643",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = assembler_df.select('features','Status').withColumnRenamed('Status','label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6aa5d20e-00d7-4aa4-a389-ab624d06a558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_indexed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "606ca3b7-a82b-4bcd-bf4c-bcde4cb92c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, LinearSVC, GBTClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2c751e3-cb2a-46cc-9d04-fd09d9c6c04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "\n",
    "model = LogisticRegressionModel.load(\"lr_model_best\")\n",
    "predictions = model.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8de09775-00af-489a-ad01-c4bcdf739144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = predictions.writeStream \\\n",
    "#     .outputMode(\"append\") \\\n",
    "#     .format(\"csv\") \\\n",
    "#     .option(\"path\", \"predictions_output/\").option(\"checkpointLocation\", \"checkpoint/\").trigger(processingTime=\"10 seconds\").start()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f8b93f7-4212-4192-acb0-b7763c5c0540",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predictions.select(\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab51be11-61fb-4e30-8f4b-bda6749eba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d674a48-f36f-4bd7-bfe8-2b7710eb307e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "def write_to_sqlite(batch_df, batch_id):\n",
    "    conn = sqlite3.connect('pred.db')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute('''CREATE TABLE IF NOT EXISTS predictions ( \n",
    "                      prediction INT)''')\n",
    "\n",
    "    pandas_df = batch_df.toPandas()\n",
    "    rows = [(row['prediction'],) for _, row in pandas_df.iterrows()]\n",
    "\n",
    "    cursor.executemany('''INSERT INTO predictions (prediction) VALUES (?)''', rows)\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d100918-8bd4-44f4-9966-1577fea5e448",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_sqlite = pred.writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .foreachBatch(write_to_sqlite) \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3e900f22-1f7f-4aef-aa07-68675e2b0ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prediction\n",
      "0             1\n",
      "1             0\n",
      "2             0\n",
      "3             0\n",
      "4             0\n",
      "..          ...\n",
      "127           0\n",
      "128           0\n",
      "129           0\n",
      "130           0\n",
      "131           0\n",
      "\n",
      "[132 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('pred.db')\n",
    "df_sql = pd.read_sql(\"SELECT * FROM predictions\", conn)\n",
    "print(df_sql)  \n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b5bc5b-b4c4-4806-bb63-6788f34e1468",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
